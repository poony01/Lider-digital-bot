// services/iaService.js
import fetch from "node-fetch";
import { getMemory, saveMemory } from "../dados/memoryService.js";

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

export async function askGPT(pergunta, userId) {
  const url = "https://api.openai.com/v1/chat/completions";
  const modelo = "gpt-4-turbo"; // ‚úÖ sempre usando o modelo avan√ßado

  // Carrega hist√≥rico do usu√°rio
  const historico = await getMemory(userId);

  // Adiciona a nova pergunta ao hist√≥rico
  historico.push({ role: "user", content: pergunta });

  // Define uma instru√ß√£o para o estilo das respostas
  const mensagens = [
    { role: "system", content: "Voc√™ √© uma assistente inteligente, educada e simp√°tica. Sempre responde com clareza e usa emojis para deixar a conversa animada üòäü§ñ‚ú®." },
    ...historico
  ];

  const body = {
    model: modelo,
    messages: mensagens,
    temperature: 0.7
  };

  const response = await fetch(url, {
    method: "POST",
    headers: {
      Authorization: `Bearer ${OPENAI_API_KEY}`, // ‚úÖ corrigido
      "Content-Type": "application/json"
    },
    body: JSON.stringify(body)
  });

  if (!response.ok) {
    const erro = await response.text();
    console.error("‚ùå Erro ao falar com a IA:", erro);
    return "üòì Desculpe, ocorreu um erro ao falar com a IA.";
  }

  const data = await response.json();
  const resposta = data.choices?.[0]?.message?.content?.trim() || "ü§ñ Sem resposta da IA.";

  // Adiciona resposta da IA ao hist√≥rico
  historico.push({ role: "assistant", content: resposta });

  // Salva hist√≥rico atualizado
  await saveMemory(userId, historico);

  return resposta;
}
